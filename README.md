### CSE465 & CSE468 under [Nabeel Mohammed (NBM)](http://ece.northsouth.edu/people/dr-nabeel-mohammed/) sir supervision<br>

------

# CSE465: Pattern Recognition and Neural Networks

[Christopher Bishop](http://people.sabanciuniv.edu/berrin/cs512/lectures/Book-Bishop-Neural%20Networks%20for%20Pattern%20Recognition.pdf) in his seminal work “Pattern Recognition and Machine Learning” describes the concept like pattern recognition deals with the automatic discovery of regularities in data through the use of computer algorithms and with the use of these regularities to take actions such as classifying the data into different categories. <br>


Video Lecture Link:

| Lecture No        | Link     | 
| ------------- |:-------------| 
| Lecture 01 | Introduction | 
| Lecture 02 | [Linear tranformation, Error Loss Functions](https://drive.google.com/file/d/17gVFUfN4Ka9dOpRAEswt2kJRN4qbN8Il/view?usp=sharing)|   
| Lecture 03 | [Gradient Descent](https://drive.google.com/file/d/1spyLYxE6mwVQt6oLjiR0gF1_k8IiOGgC/view?usp=sharing)|
| Lecture 04 | [Error calculation](https://drive.google.com/file/d/1HlqzIcMkwxTqEjwstqAcVR0hBL_OPgCJ/view?usp=sharing)|
| Lecture 05 | [Target output calculated output](https://drive.google.com/file/d/1MxyLektiQLYlDKv2jBg4hcypNiqjoVCv/view?usp=sharing)|
| Lecture 06 | [Gradient Derivative](https://drive.google.com/file/d/1324nGDz1Xk2X5H21DoU3lcOvXJItb96k/view?usp=sharing)|
| Lecture 07 | [Supervised, Unsupervised](https://drive.google.com/file/d/1Zh75PxmrzoyPC0nvZL2y1l_1fkD5cdi8/view?usp=sharing)|
| Lecture 08 | [Softmax](https://drive.google.com/file/d/1F4PIYP1pr456YS2p0BbfiRyapOsYivUB/view?usp=sharing)|
| Lecture 09 | [GEntropy, Cross-Entropy, KL-Divergence](https://drive.google.com/file/d/1EmL51b7FRsXOWgig9j2BBpbz31-88KnN/view?usp=sharing)|
| Lecture 10 | [AutoEncoder](https://drive.google.com/file/d/1ul6XZzecj_a4LnBUyZaFEQRlVUp91vXw/view?usp=sharing<br>)|
| Lecture 11 | [Intro to CNN](https://drive.google.com/file/d/1yZmDtrA2Pb7ipktO8mSXQPxSR-6rGINr/view?usp=sharing)|
| Lecture 12 | [Kernel , Filter , AlexNet Paper](https://drive.google.com/file/d/1mIEH3_RJaxlsR1H9forDzCydZO5ZMuCr/view?usp=sharing)|
| Lecture 13 | [Calculate the Shpae of CNN (Alexnet Papaer)](https://drive.google.com/file/d/1jcE5c8wjvLRBj7elgIMsye6LNsKEAW1V/view?usp=sharing)|
| Lecture 14 | [CNN padding, stride](https://drive.google.com/file/d/1rybGxgY8YluSySNux_Sn1zHD17FzjTJ4/view?usp=sharing)|
| Lecture 15 | [Dropout](https://drive.google.com/file/d/1kq9maniS-wzJ3py54-ZGxZfhobnF7VY7/view?usp=sharing)|
| Lecture 16 | [Siamese Network](https://drive.google.com/file/d/1_zcTrOfoU0mAm5sLidlOnqK31X2NBTQ0/view?usp=sharing)|
| Lecture 17 | [Triplet loss](https://drive.google.com/file/d/1GM0yzHq9uuY_TcFIbvjAHNg1js1SCZdC/view?usp=sharing)|
| Lecture 18 | [RNN](https://drive.google.com/file/d/1-scEA6TxRU4IEwQ30QqnQOoO0p8X7cLm/view?usp=sharing )|
| Lecture 19 | [Transformer](https://drive.google.com/file/d/1qh6ujiEVvE9kuarVLrNHT9U3PMfk2wJp/view?usp=sharing)|
| Lecture 20 | [LSTM](https://drive.google.com/file/d/1womR3T5yaFhtXoOxqP2oKd4wXgnTAJ2n/view?usp=sharing)|
| Lecture 21 | [Assessment discussion](https://drive.google.com/file/d/13MGWK-_v-WwBA-OykoLdGl7W0ig_SmLI/view?usp=sharing)|

--- 

# CSE468 : Computer Vision

Computer Vision, often abbreviated as CV, is defined as a field of study that seeks to develop techniques to help computers “see” and understand the content of digital images such as photographs and videos.


Video Lecture Link:

| Lecture No        | Link     | Resource     | 
| ------------- |:-------------| :---------- | 
| Lecture 01 | [Linear Algebra](https://drive.google.com/file/d/1aacmRyk6niiyYaBaXlqenELkiZIgQn7i/view?usp=sharing)| 
| Lecture 02 | [Image Classification](https://drive.google.com/file/d/12zkyt737ZolYfTCKLkVSDW6_JcpqI_uQ/view?usp=sharing)| 
| Lecture 03 | [Colour Histogram](https://drive.google.com/file/d/1cl4I22B8Hpmi6R-I3kM0sdz6HnpAo-YJ/view?usp=sharing)|
| Lecture 04 | [Gradient Descent Optimization](https://drive.google.com/file/d/1y8OjFOo9TP6NuTCX3gC0zK771sp2so2H/view?usp=sharing)|[Gradient Descent Optimization](https://ruder.io/optimizing-gradient-descent/)|
| Lecture 05 | [Loss Function & Softmax](https://drive.google.com/file/d/1b1DaHX7QSxsMeT2bQx0ZZftzhLC-Cn_Z/view?usp=sharing)|[Softmax](https://peterroelants.github.io/posts/cross-entropy-softmax/)|
| Lecture 06 | [InceptionNet Architecture](https://drive.google.com/file/d/1DRh789YAOqdX5VmN_jWjodjQZil1xH1P/view?usp=sharing)|[InceptionNet Paper](https://arxiv.org/pdf/1409.4842)|
| Lecture 07 | [AlexNet](https://drive.google.com/file/d/18bzRmEUjzrV_N-ZQnr58auJrbQ3aQ0GS/view?usp=sharing)| [AlexNet Paper](https://proceedings.neurips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)|
| Lecture 08 | [Mask R-CNN](https://drive.google.com/file/d/1iWJaQVDkFYiRGSYAh84NcyNEhZIi3Wi2/view?usp=sharing)| [Mask R-CNN Paper](https://arxiv.org/pdf/1703.06870.pdf)|
| Lecture 09 | [AutoEnoder & Decoder](https://drive.google.com/file/d/1B9FtBd_wIc7Qqy1wQvCIG0G4VOUfQQ48/view?usp=sharing)| [AutoEncoders](https://www.jeremyjordan.me/autoencoders/)|
| Lecture 10 | [Transformer](https://drive.google.com/file/d/1aq-27HLYqQUjDNJC4RCr-Y5tz1Woe8DM/view?usp=sharing)|[Image GPT](https://openai.com/blog/image-gpt/)|

